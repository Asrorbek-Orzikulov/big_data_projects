{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "id": "eOeG1er1Sjum",
    "tags": []
   },
   "source": [
    "<h6><center>Big Data Algorithms Techniques & Platforms</center></h6>\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Assignment 1: Introduction to MapReduce</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTePkMCiSjun",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Flights and Airports Data\n",
    "\n",
    "In this assignment, we are going to analyze a dataset that will include flight data. The dataset comes from <a href=\"https://www.kaggle.com/flashgordon/usa-airport-dataset\">Kaggle</a> and is in a <code>.csv</code> file. Each line of the file represents a different flight. The data collected contain:\n",
    "\n",
    "\n",
    "<code>Origin_airport</code>: Three letter airport code of the origin airport </br>\n",
    "<code>Destination_airport</code>: Three letter airport code of the destination airport</br>\n",
    "<code>Origin_city</code>: Origin city name</br>\n",
    "<code>Destination_city</code>: Destination city name</br>\n",
    "<code>Passengers</code>: Number of passengers transported from origin to destination</br>\n",
    "<code>Seats</code>: Number of seats available on flights from origin to destination</br>\n",
    "<code>Flights</code>: Number of flights between origin and destination (multiple records for one month, many with flights > 1)</br>\n",
    "<code>Distance</code>: Distance (to nearest mile) flown between origin and destination</br>\n",
    "<code>Fly_date</code>: The date (yyyymm) of flight</br>\n",
    "<code>Origin_population</code>: Origin city's population as reported by US Census</br>\n",
    "<code>Destination_population</code>: Destination city's population as reported by US Census</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assumption\n",
    "\n",
    "In this assignment, I will assume that the data is partitioned into 100,000-line chunks. That is, my `apply_map` function defined below will be applied to 100,000 lines of data at a time.\n",
    "\n",
    "As for the `shuffle` function, I used it after `apply_map` produced results for each partition and added all the key-value pairs to the `defaultdict` created for a MapReduce procedure. I did not gather the results produced by 37 `apply_map` calls into one big list just to send them to the `shuffle` function afterwards. The main reason for this was efficiency concerns. If I merged all results, I would have to store all the data in the 37 intermediate lists in RAM, and this would involve a lot of copying as the merged list grows in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "from re import compile\n",
    "from os import listdir\n",
    "\n",
    "FILENAME = \"Airports2.csv\"\n",
    "ROWS_PER_PARTITION = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total rows are 3606803.\n",
      "The number of partitions is 37.\n"
     ]
    }
   ],
   "source": [
    "with open(FILENAME, \"r\") as read_file:\n",
    "    header = read_file.readline()\n",
    "    line = read_file.readline()\n",
    "    row_count = 0\n",
    "    while line:\n",
    "        row_count += 1\n",
    "        line = read_file.readline()\n",
    "\n",
    "    print(f\"The total rows are {row_count}.\")\n",
    "    print(f\"The number of partitions is {ceil(row_count / ROWS_PER_PARTITION)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILENAME, \"r\") as read_file:  \n",
    "    header = read_file.readline()\n",
    "    file_num = 0\n",
    "    file_name = f\"data_part{file_num}.csv\"\n",
    "    partition = open(file_name, \"w\")\n",
    "    partition.write(header)\n",
    "    line = read_file.readline()\n",
    "    rows_written = 0\n",
    "    while line:\n",
    "        partition.write(line)\n",
    "        rows_written += 1\n",
    "        line = read_file.readline()\n",
    "        if rows_written % ROWS_PER_PARTITION == 0:\n",
    "            partition.close()\n",
    "            file_num = rows_written // ROWS_PER_PARTITION\n",
    "            file_name = f\"data_part{file_num}.csv\"\n",
    "            partition = open(file_name, \"w\")\n",
    "            partition.write(header)\n",
    "\n",
    "    partition.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of created files is 37.\n",
      "Sample names: ['data_part11.csv', 'data_part10.csv', 'data_part12.csv', 'data_part13.csv', 'data_part17.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames_pattern = compile(r\"^data_part.*\\.csv$\") \n",
    "filenames = list(filter(filenames_pattern.match, listdir('./')))\n",
    "print(f\"The number of created files is {len(filenames)}.\")\n",
    "print(\"Sample names:\", filenames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSGllJ6IJufD",
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Origin_airport', 'Destination_airport', 'Origin_city', 'Destination_city', 'Passengers', 'Seats', 'Flights', 'Distance', 'Fly_date', 'Origin_population', 'Destination_population', 'Org_airport_lat', 'Org_airport_long', 'Dest_airport_lat', 'Dest_airport_long'] \n",
      "\n",
      "['MHK', 'AMW', 'Manhattan: KS', 'Ames: IA', '21', '30', '1', '254', '2008-10-01', '122049', '86219', '39.140998840332', '-96.6707992553711', 'NA', 'NA'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_csv(filename):\n",
    "    \"\"\"\n",
    "    Parse a CSV file with the given `filename`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Full name of the CSV file containing records.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    list of str\n",
    "        Each line of the CSV file split into a list.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line_clean = line[:-1].replace(\"\\\"\", \"\").replace(\", \", \": \")\n",
    "            yield line_clean.split(\",\")\n",
    "\n",
    "\n",
    "contents = read_csv(FILENAME)\n",
    "print(next(contents), \"\\n\")\n",
    "print(next(contents), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(rows_gen, column_names):\n",
    "    \"\"\"\n",
    "    Find the indices of given columns.\n",
    "\n",
    "    Modifies the input generator by moving it by 1 row.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rows_gen : generator\n",
    "        Generator yielding the rows of the text file.\n",
    "    column_names : tuple of str\n",
    "        Names of the columns whose indices we need.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of int\n",
    "        List containing the index of each column.\n",
    "\n",
    "    \"\"\"\n",
    "    header = next(rows_gen)\n",
    "    indices = []\n",
    "    for column in column_names:\n",
    "        indices.append(header.index(column))\n",
    "    return indices\n",
    "\n",
    "\n",
    "def apply_map(filename, map_func, column_names):\n",
    "    \"\"\"\n",
    "    Iterate over `filename` and apply `map_func` on each line.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Full name of a text file containing records.\n",
    "    map_func : func\n",
    "        Map function returning a tuple for each line.\n",
    "    column_names : tuple of str\n",
    "        Names of the columns that `map_func` needs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        Contains tuples returned by each call of `map_func`. If the\n",
    "        map result contains None, it is not included in the list.\n",
    "    \"\"\"\n",
    "    lines = read_csv(filename)\n",
    "    column_indices = find_indices(lines, column_names)\n",
    "    map_result_list = []\n",
    "    for line in lines:\n",
    "        map_result = map_func(line, column_indices)\n",
    "        if None not in map_result:\n",
    "            map_result_list.append(map_result)\n",
    "\n",
    "    return map_result_list\n",
    "\n",
    "\n",
    "def map_reduce(columns, partitions, map_func, reduce_func, combine_func=None):\n",
    "    \"\"\"\n",
    "    Apply a MapReduce procedure on all partitions of data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : tuple of str\n",
    "        Names of the columns that `map_func` needs.\n",
    "    partitions: list of str\n",
    "        Names of the partitions of the data.\n",
    "    map_func : func\n",
    "        Map function returning a tuple for each line.\n",
    "    reduce_func : func\n",
    "        Reduce function returning a tuple for each key in the\n",
    "        dictionary created by the shuffle function.\n",
    "    combine_func : func\n",
    "        Combine function that can be applied to the result when\n",
    "        `map_func` is applied to each row of a partition.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        Contains tuples returned by each call of `reduce_func`.\n",
    "\n",
    "    \"\"\"\n",
    "    shuffle_dict = defaultdict(list)\n",
    "    for partition in partitions:\n",
    "        map_list = apply_map(partition, map_func, columns)\n",
    "        if combine_func is not None:\n",
    "            map_list = combine_func(map_list)\n",
    "#             print(map_list[:10])\n",
    "        shuffle_flights(map_list, shuffle_dict)\n",
    "\n",
    "    reduce_list = []\n",
    "    for key in shuffle_dict:\n",
    "        reduce_list.append(reduce_func(shuffle_dict, key))   \n",
    "    return reduce_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFD6BvLDNs4E",
    "tags": []
   },
   "source": [
    "## <strong> Exercise 1 - Almost-empty flights</strong> \n",
    "### <strong> 4 points </strong>\n",
    "Describe and define a MapReduce procedure that gives the number of flights that departed with at most 10% capacity (i.e. empty, 1%, 6%, etc.). \n",
    "\n",
    "The output can be of any form you like. You can use any data structure you want to support your implementation.\n",
    "### <strong> Answer </strong>\n",
    "\n",
    "My `apply_map` function will produce a list of tuples of the form (occupancy rate, flight count). After the map function, flight counts will be grouped by occupancy rate in `shuffle` and summed in `reduce`. So, after the MapReduce procedure, I have a list of 11 elements (one tuple for each occupancy rate). The only thing that remains is to sum the flight counts in that list and arrive at the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_empty(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple for flights having at most 10% occupancy rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Passengers, Seats, and\n",
    "        Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (float, int) or (None, None)\n",
    "        Each tuple is (occupancy rate, flight count) if occupancy\n",
    "        rate is at most 10%. Otherwise, it is (None, None).\n",
    "\n",
    "    \"\"\"\n",
    "    passenger_idx, seats_idx, flights_idx = column_indices\n",
    "    passengers = int(line[passenger_idx])\n",
    "    seats = int(line[seats_idx])\n",
    "    try:\n",
    "        occupancy_rate = passengers / seats\n",
    "        if occupancy_rate <= 0.1:\n",
    "            flights = int(line[flights_idx])\n",
    "            return round(occupancy_rate, 2), flights\n",
    "        else:\n",
    "            return None, None\n",
    "    except ZeroDivisionError:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "trRDY4haSjuo"
   },
   "outputs": [],
   "source": [
    "def shuffle_flights(tuples_list, shuffle_results):\n",
    "    \"\"\"\n",
    "    Take the key-value pairs returned by a map function, create a \n",
    "    list of all values corresponding to the same key and store the\n",
    "    key and the list in `shuffle_results`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples_list : list of (hashable type, any type)\n",
    "        List of tuples, where each tuple is a (key, value) pair.\n",
    "    shuffle_results : defaultdict of {hashable type : list of any type}\n",
    "        Keys are the individual values of the grouping variable, and \n",
    "        values are the lists corresponding to same key. This dictionary\n",
    "        is modified by the function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    for key, value in tuples_list:\n",
    "        shuffle_results[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_flights(pairs_dict, key):\n",
    "    \"\"\"\n",
    "    Sum all values corresponding to the given key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pairs_dict : dict of {hashable type : list of int}\n",
    "        Keys are the individual values of the grouping variable,\n",
    "        and values are the lists corresponding to same key.\n",
    "    key : hashable type\n",
    "        Individual value of the grouping variable for which we\n",
    "        need a sum.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (hashable type, int)\n",
    "        tuple of the form (key, sum of all values).\n",
    "\n",
    "    \"\"\"\n",
    "    values_list = pairs_dict[key]\n",
    "    values_sum = sum(values_list)\n",
    "    return key, values_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 99198),\n",
       " (0.07, 26468),\n",
       " (0.06, 21925),\n",
       " (0.04, 15442),\n",
       " (0.02, 10080),\n",
       " (0.03, 12149),\n",
       " (0.05, 19344),\n",
       " (0.09, 36472),\n",
       " (0.1, 21950),\n",
       " (0.08, 28528),\n",
       " (0.01, 10677)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns1 = (\"Passengers\", \"Seats\", \"Flights\")\n",
    "reduce_empty_simple = map_reduce(\n",
    "    columns1, filenames, map_empty, reduce_flights)\n",
    "reduce_empty_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of almost empty flights is 302233.\n"
     ]
    }
   ],
   "source": [
    "reduce_empty_sum = sum(x[1] for x in reduce_empty_simple)\n",
    "print(f\"The number of almost empty flights is {reduce_empty_sum}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> Combine function </strong>\n",
    "In this case, it is possible to use the `combine` operator. The reason is the same key (`occupancy_rate`) is likely to be repeated several times inside one 100,000-line chunk. Also, the reduce function (`sum`) is commutative and associative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sum(tuples_list):\n",
    "    \"\"\"\n",
    "    Take the key-value pairs returned by a map function for one\n",
    "    partition and sum the values by key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples_list : list of (hashable type, any type)\n",
    "        List of tuples, where each tuple is a (key, value) pair.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of (hashable type, int)\n",
    "        Each tuple is of the form (key, sum of all values).\n",
    "\n",
    "    \"\"\"\n",
    "    key_value_dict = defaultdict(int)\n",
    "    for key, value in tuples_list:\n",
    "        key_value_dict[key] += value\n",
    "\n",
    "    return list(key_value_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 99198),\n",
       " (0.07, 26468),\n",
       " (0.06, 21925),\n",
       " (0.04, 15442),\n",
       " (0.02, 10080),\n",
       " (0.03, 12149),\n",
       " (0.05, 19344),\n",
       " (0.09, 36472),\n",
       " (0.1, 21950),\n",
       " (0.08, 28528),\n",
       " (0.01, 10677)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_empty_combine = map_reduce(\n",
    "    columns1, filenames, map_empty, reduce_flights, combine_sum)\n",
    "reduce_empty_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of almost empty flights is 302233.\n"
     ]
    }
   ],
   "source": [
    "reduce_empty_sum = sum(x[1] for x in reduce_empty_combine)\n",
    "print(f\"The number of almost empty flights is {reduce_empty_sum}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqa7Q8TASjuu",
    "tags": []
   },
   "source": [
    "## <strong> Exercise 2 - Top five destination airports </strong>\n",
    "### <strong> 4 points </strong>\n",
    "\n",
    "Provide now a function that lists the top five destination <strong>airports</strong>: the ones that have the highest number of incoming flights. Implement an algorithm that uses the MapReduce procedure.\n",
    "\n",
    "### <strong> Answer </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YA5It5kQSjuv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_flights(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple of (group variable, flight count).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of the grouping variable\n",
    "        and the Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (hashable type, int)\n",
    "        Hashable type is the type of the grouping variable.\n",
    "\n",
    "    \"\"\"\n",
    "    group_var_idx, flights_idx = column_indices\n",
    "    group_var = line[group_var_idx]\n",
    "    flight_count = int(line[flights_idx])\n",
    "    return group_var, flight_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `shuffle` and `reduce` operations, we can take advantage of functions written for Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top-5 airports are [('ORD', 6896285), ('ATL', 6544759), ('DFW', 5987886), ('LAX', 4096702), ('DTW', 3448042)]\n"
     ]
    }
   ],
   "source": [
    "columns2 = (\"Destination_airport\", \"Flights\")\n",
    "reduce_top_airports = map_reduce(\n",
    "    columns2, filenames, map_flights, reduce_flights, combine_sum)\n",
    "\n",
    "reduce_top_airports.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"The top-5 airports are\", reduce_top_airports[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <strong> Exercise 3 - Top 5 destination cities </strong>\n",
    "### <strong> 2 points </strong>\n",
    "\n",
    "Try to reuse the code you run before and define a function that lists the top five destination cities: the ones that have the highest number of incoming flights. Implement an algorithm that uses the MapReduce procedure.\n",
    "\n",
    "### <strong> Answer </strong>\n",
    "Since this question is almost identical to the previous one, the only thing to do is to use `Destination_city` column instead of the `Destination_airport` column. We do not need to write new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top-5 cities are [('Chicago: IL', 8357958), ('Dallas: TX', 6957427), ('Atlanta: GA', 6544880), ('Houston: TX', 4350447), ('New York: NY', 4317734)]\n"
     ]
    }
   ],
   "source": [
    "columns3 = (\"Destination_city\", \"Flights\")\n",
    "reduce_top_cities = map_reduce(\n",
    "    columns3, filenames, map_flights, reduce_flights, combine_sum)\n",
    "reduce_top_cities.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"The top-5 cities are\", reduce_top_cities[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwbGGzCg2WlY",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <strong> Exercise 4 - Top five connections by month</strong>\n",
    "### <strong> 4 points </strong>\n",
    "\n",
    "Try to reuse the code you run before and define now a function that lists the top five connections by each month: the top five pairs of cities that have the most number of flights. The function should take into account the flights from A to B and from B to A by month/year. Implement an algorithm that uses the MapReduce procedure.\n",
    "\n",
    "### <strong> Answer </strong>\n",
    "\n",
    "Here, we re-use the `shuffle` function written for Exercise 1. The `apply_map` function returns a list of tuples of the form (date, (cities, flight count)). Then, all flights that took place in the same month/year will be included into one list by the `shuffle` function. Finally, `reduce` will sum the flights that took place between the same two cities and return the top-5 connections for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cHbkfinx27Dx"
   },
   "outputs": [],
   "source": [
    "def map_connections(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple for flights between two cities by month/year.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Origin_city, Destination_city,\n",
    "        Flights, and Fly_date columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (str, (str, int))\n",
    "        Each tuple is (date, (cities, flight count))\n",
    "\n",
    "    \"\"\"\n",
    "    source_idx, destination_idx, flights_idx, date_idx = column_indices\n",
    "    source = line[source_idx]\n",
    "    destination = line[destination_idx]\n",
    "    flights = int(line[flights_idx])\n",
    "    date = line[date_idx][:-3]\n",
    "    if source > destination:\n",
    "        destination, source = source, destination  # ordering pairs alphabetically\n",
    "\n",
    "    cities = source + \" - \" + destination\n",
    "    return date, (cities, flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_connections(flights_dict, date):\n",
    "    \"\"\"\n",
    "    Find the top-5 flight directions for the given date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flights_dict : dict of {str : list of (str, int)}\n",
    "        Keys are dates, and values are lists of tuples of the\n",
    "        form (two cities, flights between them).\n",
    "    date : str\n",
    "        Date of the form yyyy-mm for which we need the top-5 cities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (str, list of (str, int))\n",
    "         Tuple is (date, list of (two cities, total flights between them))\n",
    "\n",
    "    \"\"\"\n",
    "    all_flights_in_month = flights_dict[date]\n",
    "    flight_counts = defaultdict(int)\n",
    "    for cities, flights in all_flights_in_month:\n",
    "        flight_counts[cities] += flights\n",
    "\n",
    "    flight_counts_list = sorted(\n",
    "        flight_counts.items(),\n",
    "        key=lambda item: item[1],\n",
    "        reverse=True)\n",
    "    return date, flight_counts_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1990-01',\n",
       "  [('Dallas: TX - Houston: TX', 4602),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3812),\n",
       "   ('Honolulu: HI - Kahului: HI', 3285),\n",
       "   ('Portland: OR - Seattle: WA', 3162),\n",
       "   ('Chicago: IL - Detroit: MI', 3081)]),\n",
       " ('1990-02',\n",
       "  [('Dallas: TX - Houston: TX', 4135),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3168),\n",
       "   ('Honolulu: HI - Kahului: HI', 2991),\n",
       "   ('Chicago: IL - Detroit: MI', 2755),\n",
       "   ('Portland: OR - Seattle: WA', 2741)]),\n",
       " ('1990-03',\n",
       "  [('Dallas: TX - Houston: TX', 4636),\n",
       "   ('Honolulu: HI - Kahului: HI', 3563),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3533),\n",
       "   ('Portland: OR - Seattle: WA', 3172),\n",
       "   ('Chicago: IL - Detroit: MI', 3031)]),\n",
       " ('1990-04',\n",
       "  [('Dallas: TX - Houston: TX', 4518),\n",
       "   ('Honolulu: HI - Kahului: HI', 3941),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3545),\n",
       "   ('Chicago: IL - Detroit: MI', 3042),\n",
       "   ('Portland: OR - Seattle: WA', 3029)]),\n",
       " ('1990-05',\n",
       "  [('Dallas: TX - Houston: TX', 4786),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 4207),\n",
       "   ('Honolulu: HI - Kahului: HI', 3980),\n",
       "   ('Chicago: IL - Detroit: MI', 3189),\n",
       "   ('Portland: OR - Seattle: WA', 3185)])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns4 = (\"Origin_city\", \"Destination_city\", \"Flights\", \"Fly_date\")\n",
    "reduce_connections_simple = map_reduce(\n",
    "    columns4, filenames, map_connections, reduce_connections)\n",
    "reduce_connections_simple.sort()  # sorting chronologically\n",
    "reduce_connections_simple[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> Combine function </strong>\n",
    "In this case, it is possible to use the `combine` operator. The reason is the reduce function includes `sum`, which is commutative and associative. So, this part of the work can be done inside the `combine` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_value_count(tuples_list):\n",
    "    \"\"\"\n",
    "    Take the key-value pairs returned by a map function for one\n",
    "    partition and sum `value[1]` for `value[0]` by key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples_list : list of (str, (str or int, int))\n",
    "        Each tuple is a (key, (sub key, flight count)).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of (str, (str or int, int))\n",
    "        Each tuple is a (key, (sub key, partition flight count)).\n",
    "\n",
    "    \"\"\"\n",
    "    key_value_dict = defaultdict(int)\n",
    "    for key, value_tuple in tuples_list:\n",
    "        sub_key, flights = value_tuple\n",
    "        new_key = (key, sub_key)\n",
    "        key_value_dict[new_key] += flights\n",
    "\n",
    "    combine_list = [(key[0], (key[1], value))\n",
    "                    for key, value in key_value_dict.items()]\n",
    "    return combine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1990-01',\n",
       "  [('Dallas: TX - Houston: TX', 4602),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3812),\n",
       "   ('Honolulu: HI - Kahului: HI', 3285),\n",
       "   ('Portland: OR - Seattle: WA', 3162),\n",
       "   ('Chicago: IL - Detroit: MI', 3081)]),\n",
       " ('1990-02',\n",
       "  [('Dallas: TX - Houston: TX', 4135),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3168),\n",
       "   ('Honolulu: HI - Kahului: HI', 2991),\n",
       "   ('Chicago: IL - Detroit: MI', 2755),\n",
       "   ('Portland: OR - Seattle: WA', 2741)]),\n",
       " ('1990-03',\n",
       "  [('Dallas: TX - Houston: TX', 4636),\n",
       "   ('Honolulu: HI - Kahului: HI', 3563),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3533),\n",
       "   ('Portland: OR - Seattle: WA', 3172),\n",
       "   ('Chicago: IL - Detroit: MI', 3031)]),\n",
       " ('1990-04',\n",
       "  [('Dallas: TX - Houston: TX', 4518),\n",
       "   ('Honolulu: HI - Kahului: HI', 3941),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 3545),\n",
       "   ('Chicago: IL - Detroit: MI', 3042),\n",
       "   ('Portland: OR - Seattle: WA', 3029)]),\n",
       " ('1990-05',\n",
       "  [('Dallas: TX - Houston: TX', 4786),\n",
       "   ('Los Angeles: CA - San Francisco: CA', 4207),\n",
       "   ('Honolulu: HI - Kahului: HI', 3980),\n",
       "   ('Chicago: IL - Detroit: MI', 3189),\n",
       "   ('Portland: OR - Seattle: WA', 3185)])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_connections_combine = map_reduce(\n",
    "    columns4, filenames, map_connections, reduce_connections, combine_value_count)\n",
    "reduce_connections_combine.sort()  # sorting chronologically\n",
    "reduce_connections_combine[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIqc-JJDbdgX",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <strong> Exercise 5 - Number of full flights</strong>\n",
    "### <strong> 2 points </strong>\n",
    "<p align=\"justify\">\n",
    "Describe and implement an algorithm that, following MapReduce procedure, shows how many full flights have departed. This exercise gives you an idea about how many times you can re-use code in MapReduce with minimum effort for repetitive analysis.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "### <strong> Answer </strong>\n",
    "\n",
    "To write a function that we can use for both Exercise 5 and Exercise 6, I will modify the `map` function of Exercise 1 slightly. This function will basically return (1, flight count) if the flight was full and (0, flight count) if it was not full. For the `shuffle` and `reduce` operations, we can take advantage of functions written for Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ved9CtvMSju0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_full(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple for flights depending on their occupancy rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Passengers, Seats, and\n",
    "        Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (int, int) or (None, None)\n",
    "        Each tuple is (dummy key, flight count). The dummy key\n",
    "        is 1 if the occupancy rate is 100% and 0 otherwise. The\n",
    "        return values is (None, None) if seats count is zero.\n",
    "\n",
    "    \"\"\"\n",
    "    passenger_idx, seats_idx, flights_idx = column_indices\n",
    "    passengers = int(line[passenger_idx])\n",
    "    seats = int(line[seats_idx])\n",
    "    try:\n",
    "        occupancy_rate = passengers / seats\n",
    "        flight_count = int(line[flights_idx])\n",
    "        if occupancy_rate == 1:\n",
    "            return 1, flight_count\n",
    "        else:\n",
    "            return 0, flight_count\n",
    "    except ZeroDivisionError:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 130848882), (1, 38507)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_full = map_reduce(columns1, filenames, map_full, reduce_flights)\n",
    "reduce_full.sort()\n",
    "reduce_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of full flights is 38507.\n"
     ]
    }
   ],
   "source": [
    "number_full = reduce_full[1][1]\n",
    "print(f\"The number of full flights is {number_full}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The share of full flights is 0.03%.\n"
     ]
    }
   ],
   "source": [
    "share_full = reduce_full[1][1] / (reduce_full[0][1]+reduce_full[1][1])\n",
    "print(f\"The share of full flights is {share_full*100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYM8qhAuSju5",
    "tags": []
   },
   "source": [
    "## <strong> Exercise 6 -  Percentage of full flights </strong>\n",
    "### <strong> 4 points </strong>\n",
    "\n",
    "<p align=\"justify\">\n",
    "Describe and implement a MapReduce procedure that gives, for each city, the percentage of full flights that have departed.\n",
    "\n",
    "Notice that this exercise shares some similarities with one of the previous exercises. Think how and if you can modify (generalize) one of the functions already implemented before. \n",
    "</font>\n",
    "</p>\n",
    "\n",
    "### <strong> Answer </strong>\n",
    "Inside the `map` function of this exercise, I will delegate most of the computation to the `map` function of Exercise 5. After `apply_map` produces a list of tuples of the form (city, (is_full, flight count)), all flights that departed from the same city will be included into one list in `shuffle`. (Once again, the `shuffle` function of Exercise 1 will be re-used.) Finally, `reduce` computes the proportion (which is a weighted average of zeros and ones) of flights that were full by city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zPywU-Hu6UF7"
   },
   "outputs": [],
   "source": [
    "def map_proportion(line, column_indices):\n",
    "    \"\"\"\n",
    "    For each origin city, create a tuple depending on the \n",
    "    occupancy rate of flights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Origin_city, Passengers,\n",
    "        Seats, and Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (str, (int, int)) or (None, (None, None))\n",
    "        Returns (city, (1, flight count)) if the flight was full,\n",
    "        (city, (0, flight count)) if the flight wasn't full, and\n",
    "        (None, (None, None)) if the number of seats was zero.\n",
    "\n",
    "    \"\"\"\n",
    "    city_idx = column_indices[0]\n",
    "    city = line[city_idx]\n",
    "    new_column_indices = column_indices[1:]\n",
    "    is_full_tuple = map_full(line, new_column_indices)\n",
    "    if is_full_tuple != (None, None):\n",
    "        return city, is_full_tuple\n",
    "    else:\n",
    "        return None, is_full_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_proportion(counts_dict, key):\n",
    "    \"\"\"\n",
    "    Compute the weighted average of all values for the given key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts_dict : dict of {hashable type : list of tuple}\n",
    "        Keys are the individual values of the grouping variable,\n",
    "        and values are the lists of tuples corresponding to same key.\n",
    "        The first element of each tuple is the value to be averaged,\n",
    "        and the second element is the corresponding weight.\n",
    "    key : hashable type\n",
    "        Individual value of the grouping variable for which we\n",
    "        need a weighted average.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (hashable type, float)\n",
    "        tuple of the form (key, weighted average of all values).\n",
    "\n",
    "    \"\"\"\n",
    "    value_weight_list = counts_dict[key]\n",
    "    sum_of_weights = 0\n",
    "    weighted_sum = 0\n",
    "    for value, weight in value_weight_list:\n",
    "        weighted_sum += value * weight\n",
    "        sum_of_weights += weight\n",
    "\n",
    "    weighted_mean = weighted_sum / sum_of_weights\n",
    "    return key, weighted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Marshall: TX', 100.0),\n",
       " ('Shelton: WA', 50.0),\n",
       " ('Seymour: IN', 50.0),\n",
       " ('Lawrence: KS', 40.0),\n",
       " ('Napa: CA', 16.666666666666664),\n",
       " ('Mansfield: OH', 10.0),\n",
       " ('Scottsbluff: NE', 8.539944903581267)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns6 = (\"Origin_city\", \"Passengers\", \"Seats\", \"Flights\")\n",
    "reduce_proportion_simple = map_reduce(\n",
    "    columns6, filenames, map_proportion, reduce_proportion)\n",
    "reduce_percent_simple = [(key, share*100) for key, share in reduce_proportion_simple]\n",
    "reduce_percent_simple.sort(key=lambda x: x[1], reverse=True)\n",
    "reduce_percent_simple[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o-3JT1L659s"
   },
   "source": [
    "### <strong> Combine function </strong>\n",
    "In this case, it is possible to use the `combine` operator. The reason is the `reduce` function needs to sum the flight counts for full and not full flights. This part of the work can be done inside the `combine` function, which we already defined for Exercise 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Marshall: TX', 100.0),\n",
       " ('Shelton: WA', 50.0),\n",
       " ('Seymour: IN', 50.0),\n",
       " ('Lawrence: KS', 40.0),\n",
       " ('Napa: CA', 16.666666666666664),\n",
       " ('Mansfield: OH', 10.0),\n",
       " ('Scottsbluff: NE', 8.539944903581267)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_proportion_combine = map_reduce(\n",
    "    columns6, filenames, map_proportion, reduce_proportion, combine_value_count)\n",
    "reduce_percent_combine = [(key, share*100) for key, share in reduce_proportion_combine]\n",
    "reduce_percent_combine.sort(key=lambda x: x[1], reverse=True)\n",
    "reduce_percent_combine[:7]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "ass1_mapReduce_2021_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "name": "BE4-Spark.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
