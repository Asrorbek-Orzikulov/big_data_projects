{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "id": "eOeG1er1Sjum",
    "tags": []
   },
   "source": [
    "<h6><center>Big Data Algorithms Techniques & Platforms</center></h6>\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Assignment 1: Introduction to MapReduce</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTePkMCiSjun",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Flights and Airports Data\n",
    "\n",
    "In this assignment, we are going to analyze a dataset that will include flight data. The dataset comes from <a href=\"https://www.kaggle.com/flashgordon/usa-airport-dataset\">Kaggle</a> and is in a <code>.csv</code> file. Each line of the file represents a different flight. The data collected contain:\n",
    "\n",
    "\n",
    "<code>Origin_airport</code>: Three letter airport code of the origin airport </br>\n",
    "<code>Destination_airport</code>: Three letter airport code of the destination airport</br>\n",
    "<code>Origin_city</code>: Origin city name</br>\n",
    "<code>Destination_city</code>: Destination city name</br>\n",
    "<code>Passengers</code>: Number of passengers transported from origin to destination</br>\n",
    "<code>Seats</code>: Number of seats available on flights from origin to destination</br>\n",
    "<code>Flights</code>: Number of flights between origin and destination (multiple records for one month, many with flights > 1)</br>\n",
    "<code>Distance</code>: Distance (to nearest mile) flown between origin and destination</br>\n",
    "<code>Fly_date</code>: The date (yyyymm) of flight</br>\n",
    "<code>Origin_population</code>: Origin city's population as reported by US Census</br>\n",
    "<code>Destination_population</code>: Destination city's population as reported by US Census</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption\n",
    "\n",
    "In this assignment, I will assume that the data is partitioned into 100,000-line chunks. That is, all `map` functions defined below will be applied to 100,000 lines of data at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "from re import compile\n",
    "from os import listdir\n",
    "\n",
    "FILENAME = \"Airports2.csv\"\n",
    "ROWS_PER_PARTITION = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total rows are 3606803.\n",
      "The number of partitions is 37.\n"
     ]
    }
   ],
   "source": [
    "with open(FILENAME, \"r\") as read_file:\n",
    "    header = read_file.readline()\n",
    "    line = read_file.readline()\n",
    "    row_count = 0\n",
    "    while line:\n",
    "        row_count += 1\n",
    "        line = read_file.readline()\n",
    "\n",
    "    print(f\"The total rows are {row_count}.\")\n",
    "    print(f\"The number of partitions is {ceil(row_count / ROWS_PER_PARTITION)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILENAME, \"r\") as read_file:  \n",
    "    header = read_file.readline()\n",
    "    file_num = 0\n",
    "    file_name = f\"data_part{file_num}.csv\"\n",
    "    partition = open(file_name, \"w\")\n",
    "    partition.write(header)\n",
    "    line = read_file.readline()\n",
    "    rows_written = 0\n",
    "    while line:\n",
    "        partition.write(line)\n",
    "        rows_written += 1\n",
    "        line = read_file.readline()\n",
    "        if rows_written % ROWS_PER_PARTITION == 0:\n",
    "            partition.close()\n",
    "            file_num = rows_written // ROWS_PER_PARTITION\n",
    "            file_name = f\"data_part{file_num}.csv\"\n",
    "            partition = open(file_name, \"w\")\n",
    "            partition.write(header)\n",
    "\n",
    "    partition.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of created files is 37.\n",
      "Sample names: ['data_part11.csv', 'data_part10.csv', 'data_part12.csv', 'data_part13.csv', 'data_part17.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames_pattern = compile(r\"^data_part.*\\.csv$\") \n",
    "filenames = list(filter(filenames_pattern.match, listdir('./')))\n",
    "print(f\"The number of created files is {len(filenames)}.\")\n",
    "print(\"Sample names:\", filenames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSGllJ6IJufD"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    \"\"\"\n",
    "    Parse a CSV file with the given `filename`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Full name of the CSV file containing records.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    list of str\n",
    "        Each line of the CSV file split into a list.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line_clean = line[:-1].replace(\"\\\"\", \"\").replace(\", \", \": \")\n",
    "            yield line_clean.split(\",\")\n",
    "\n",
    "\n",
    "contents = read_csv(FILENAME)\n",
    "next(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in contents:\n",
    "    if i < 5:\n",
    "        print(row)\n",
    "        i += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(rows_gen, column_names):\n",
    "    \"\"\"\n",
    "    Find the indices of given columns.\n",
    "\n",
    "    Modifies the input generator by moving it by 1 row.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rows_gen : generator\n",
    "        Generator yielding the rows of the text file.\n",
    "    column_names : tuple of str\n",
    "        Names of the columns whose indices we need.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of int\n",
    "        List containing the index of each column.\n",
    "\n",
    "    \"\"\"\n",
    "    header = next(rows_gen)\n",
    "    indices = []\n",
    "    for column in column_names:\n",
    "        indices.append(header.index(column))\n",
    "    return indices\n",
    "\n",
    "\n",
    "def apply_map(filename, map_func, column_names):\n",
    "    \"\"\"\n",
    "    Iterate over `filename` and apply `map_func` on each line.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Full name of a text file containing records.\n",
    "    map_func : func\n",
    "        Map function returning a tuple for each line.\n",
    "    column_names : tuple of str\n",
    "        Names of the columns that `map_func` needs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        Contains tuples returned by each call of `map_func`. If the\n",
    "        map result contains None, it is not included in the list.\n",
    "    \"\"\"\n",
    "    lines = read_csv(filename)\n",
    "    column_indices = find_indices(lines, column_names)\n",
    "    map_result_list = []\n",
    "    for line in lines:\n",
    "        map_result = map_func(line, column_indices)\n",
    "        if None not in map_result:\n",
    "            map_result_list.append(map_result)\n",
    "\n",
    "    return map_result_list\n",
    "\n",
    "\n",
    "def apply_reduce(tuples_dict, reduce_func):\n",
    "    \"\"\"\n",
    "    Iterate over `tuples_dict` and apply `reduce_func` on each key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples_dict : dict of tuples\n",
    "        Dictionary of key-value pairs produced by the corresponding\n",
    "        shuffle function.\n",
    "    reduce_func : func\n",
    "        Reduce function returning a tuple for each key in `tuples_dict`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        Contains tuples returned by each call of `reduce_func`.\n",
    "\n",
    "    \"\"\"\n",
    "    reduce_list = []\n",
    "    for key in tuples_dict:\n",
    "        reduce_list.append(reduce_func(tuples_dict, key))\n",
    "\n",
    "    return reduce_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFD6BvLDNs4E",
    "tags": []
   },
   "source": [
    "### <strong> Exercise 1 - Almost-empty flights</strong> \n",
    "#### <strong> 4 points </strong>\n",
    "Describe and define a MapReduce procedure that gives the number of flights that departed with at most 10% capacity (i.e. empty, 1%, 6%, etc.). \n",
    "\n",
    "The output can be of any form you like. You can use any data structure you want to support your implementation.\n",
    "#### <strong> Answer </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_empty(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple for flights having at most 10% occupancy rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Passengers, Seats, and\n",
    "        Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (float, int) or (None, None)\n",
    "        Each tuple is (occupancy rate, flight count) if occupancy\n",
    "        rate is at most 10%. Otherwise, it is (None, None).\n",
    "\n",
    "    \"\"\"\n",
    "    passenger_idx, seats_idx, flights_idx = column_indices\n",
    "    passengers = int(line[passenger_idx])\n",
    "    seats = int(line[seats_idx])\n",
    "    try:\n",
    "        occupancy_rate = passengers / seats\n",
    "        if occupancy_rate <= 0.1:\n",
    "            flights = int(line[flights_idx])\n",
    "            return round(occupancy_rate, 2), flights\n",
    "        else:\n",
    "            return None, None\n",
    "    except ZeroDivisionError:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "columns1 = (\"Passengers\", \"Seats\", \"Flights\")\n",
    "map_empty_result = apply_map(FILENAME, map_empty, columns1)\n",
    "map_empty_result[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trRDY4haSjuo"
   },
   "outputs": [],
   "source": [
    "def shuffle_flights(tuples_list):\n",
    "    \"\"\"\n",
    "    Take the key-value pairs created by a map function and\n",
    "    create a list of all values corresponding to the same key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples_list : list of (hashable type, any type)\n",
    "        List of tuples, where each tuple is a (key, value) pair.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    defaultdict of {hashable type : list of any type}\n",
    "        Keys are the individual values of the grouping variable,\n",
    "        and values are the lists corresponding to same key.\n",
    "\n",
    "    \"\"\"\n",
    "    pairs_dict = defaultdict(list)\n",
    "    for key, value in tuples_list:\n",
    "        pairs_dict[key].append(value)\n",
    "\n",
    "    return pairs_dict\n",
    "\n",
    "\n",
    "shuffle_empty_result = shuffle_flights(map_empty_result)\n",
    "shuffle_empty_result[0.09][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_flights(pairs_dict, key):\n",
    "    \"\"\"\n",
    "    Sum all values corresponding to the given key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pairs_dict : dict of {hashable type : list of int}\n",
    "        Keys are the individual values of the grouping variable,\n",
    "        and values are the lists corresponding to same key.\n",
    "    key : hashable type\n",
    "        Individual value of the grouping variable for which we\n",
    "        need a sum.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (hashable type, int)\n",
    "        tuple of the form (key, sum of all values).\n",
    "\n",
    "    \"\"\"\n",
    "    values_list = pairs_dict[key]\n",
    "    values_sum = sum(values_list)\n",
    "    return key, values_sum\n",
    "\n",
    "\n",
    "reduce_empty_partial = apply_reduce(shuffle_empty_result, reduce_flights)\n",
    "reduce_empty_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_empty_full = sum(x[1] for x in reduce_empty_partial)\n",
    "print(f\"The number of almost empty flights is {reduce_empty_full}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong> Combine function </strong>\n",
    "In this particular case, it is not possible to use the `combine` operator. If processed parallelly by different machines, each input line produces only one key-value pair of (occupancy rate, flight count) after the one-to-one `map` function. That's why there are no other key-value pairs to combine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqa7Q8TASjuu"
   },
   "source": [
    "### <strong> Exercise 2 - Top five destination airports </strong>\n",
    "### <strong> 4 points </strong>\n",
    "\n",
    "Provide now a function that lists the top five destination <strong>airports</strong>: the ones that have the highest number of incoming flights. Implement an algorithm that uses the MapReduce procedure.\n",
    "\n",
    "#### <strong> Answer </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YA5It5kQSjuv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_flights(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple of (group variable, flight count).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of the grouping variable\n",
    "        and the Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (hashable type, int)\n",
    "        Hashable type is the type of the grouping variable.\n",
    "\n",
    "    \"\"\"\n",
    "    group_var_idx, flights_idx = column_indices\n",
    "    group_var = line[group_var_idx]\n",
    "    flight_count = int(line[flights_idx])\n",
    "    return group_var, flight_count\n",
    "\n",
    "\n",
    "columns2 = (\"Destination_airport\", \"Flights\")\n",
    "map_top_airports = apply_map(FILENAME, map_flights, columns2)\n",
    "map_top_airports[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `shuffle` and `reduce` operations, we can take advantage of functions written for Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_top_airports = shuffle_flights(map_top_airports)\n",
    "shuffle_top_airports[\"END\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_top_airports = apply_reduce(shuffle_top_airports, reduce_flights)\n",
    "reduce_top_airports.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"The top-5 airports are\", reduce_top_airports[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4p2_JHi0NHw"
   },
   "source": [
    "### <strong> Exercise 3 - Top 5 destination cities </strong>\n",
    "#### <strong>  2 points </strong>\n",
    "\n",
    "Try to reuse the code you run before and define a function that lists the top five destination <strong>cities</strong>: the ones that have the highest number of incoming flights. Implement an algorithm that uses the MapReduce procedure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong> Answer </strong>\n",
    "\n",
    "Since this question is almost identical to the previous one, the only thing to do is to use `Destination_city` column instead of the `Destination_airport` column. We do not need to write new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOJ603rJ0z4x"
   },
   "outputs": [],
   "source": [
    "columns3 = (\"Destination_city\", \"Flights\")\n",
    "map_top_cities = apply_map(FILENAME, map_flights, columns3)\n",
    "map_top_cities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_top_cities = shuffle_flights(map_top_cities)\n",
    "shuffle_top_cities[\"Ames: IA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_top_cities = apply_reduce(shuffle_top_cities, reduce_flights)\n",
    "reduce_top_cities.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"The top-5 cities are\", reduce_top_cities[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk34RU8JSjuz"
   },
   "source": [
    "## Statistics on flights\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "Now we want to run some more complex analysis on the flights. \n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwbGGzCg2WlY"
   },
   "source": [
    "### <strong> Exercise 4 - Top five connections by month</strong>\n",
    "#### <strong> 4 points </strong>\n",
    "\n",
    "Try to reuse the code you run before and define now a function that lists the top five connections by each month: the top five pairs of cities that have the most number of flights. The function should take into account the flights from A to B and from B to A by month/year. Implement an algorithm that uses the MapReduce procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong> Answer </strong>\n",
    "\n",
    "For this question, we will use a two-step MapReduce procedure. After the first step, we will have the total number of flights between two cities in each month/year. After the second step, we will have the top-5 connected cities in each month/year. \n",
    "\n",
    "Here, we re-use the `shuffle` function twice and the `reduce` function once. (Both were written for Exercise 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHbkfinx27Dx"
   },
   "outputs": [],
   "source": [
    "def map_connections1(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple for flights between two cities by month/year.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Origin_city, Destination_city,\n",
    "        Flights, and Fly_date columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of ((str, str, str), int)\n",
    "        Each tuple is ((date, city1, city2), flight count).\n",
    "\n",
    "    \"\"\"\n",
    "    source_idx, destination_idx, flights_idx, date_idx = column_indices\n",
    "    source = line[source_idx]\n",
    "    destination = line[destination_idx]\n",
    "    flights = int(line[flights_idx])\n",
    "    date = line[date_idx][:-3]\n",
    "    if source > destination:\n",
    "        destination, source = source, destination  # ordering pairs alphabetically\n",
    "\n",
    "    joint_key = (date, source, destination)\n",
    "    return joint_key, flights\n",
    "\n",
    "\n",
    "columns4 = (\"Origin_city\", \"Destination_city\", \"Flights\", \"Fly_date\")\n",
    "map_connections_result1 = apply_map(FILENAME, map_connections1, columns4)\n",
    "map_connections_result1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_connections_result1 = shuffle_flights(map_connections_result1)\n",
    "shuffle_connections_result1[(\"1990-02\", \"Bend: OR\", \"Seattle: WA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_connections_result1 = apply_reduce(shuffle_connections_result1, reduce_flights)\n",
    "reduce_connections_result1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_connections2(key, flights):\n",
    "    \"\"\"\n",
    "    Regroup flights between two cities by month/year.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : tuple of (str, str, str)\n",
    "        A tuple of the form (date, city1, city2)\n",
    "    flights : int\n",
    "        Count of flights between the two cities by month/year.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (str, (str, str, int))\n",
    "        Each tuple is of the form (date, (city1, city2, count)).\n",
    "\n",
    "    \"\"\"\n",
    "    date, source, destination = key\n",
    "    new_value = (source, destination, flights)\n",
    "    return date, new_value\n",
    "\n",
    "\n",
    "map_connections_result2 = []\n",
    "for key, flights in reduce_connections_result1:\n",
    "    map_result = map_connections2(key, flights)\n",
    "    map_connections_result2.append(map_result)\n",
    "\n",
    "map_connections_result2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_connections_result2 = shuffle_flights(map_connections_result2)\n",
    "shuffle_connections_result2['1999-01'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_connections2(flights_dict, date):\n",
    "    \"\"\"\n",
    "    Find the top-5 cities with the most flights for the given date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flights_dict : dict of {str : list of (str, str, int)}\n",
    "        Keys are dates, and values are lists of tuples of the form\n",
    "        (city1, city2, count).\n",
    "    date : str\n",
    "        Date of the form yyyy-mm for which we need the top-5 cities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (str, list of (str, str, int))\n",
    "        A tuple of the form (date, list of (city1, city2, count)).\n",
    "\n",
    "    \"\"\"\n",
    "    flight_info = flights_dict[date]\n",
    "    flight_info.sort(key=lambda x: x[2], reverse=True)\n",
    "    return date, flight_info[:5]\n",
    "\n",
    "\n",
    "reduce_connections_result2 = apply_reduce(\n",
    "    shuffle_connections_result2, reduce_connections2)\n",
    "reduce_connections_result2.sort()\n",
    "reduce_connections_result2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VBatJCf22oZ"
   },
   "source": [
    "#### <strong> Combine function </strong>\n",
    "\n",
    "In this particular case, it is not possible to use the `combine` operator. If processed parallelly by different machines, each input produces only one key-value pair after the corresponding `map` function. In other words, both map functions are one-to-one. That's why there are no other key-value pairs to combine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIqc-JJDbdgX"
   },
   "source": [
    "### <strong> Exercise 5 - Number of full flights</strong>\n",
    "#### <strong> 2 points </strong>\n",
    "<p align=\"justify\">\n",
    "Describe and implement an algorithm that, following MapReduce procedure, shows how many full flights have departed. This exercise gives you an idea about how many times you can re-use code in MapReduce with minimum effort for repetitive analysis.\n",
    "</font>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong> Answer </strong>\n",
    "\n",
    "To write a function that we can use for both Exercise 5 and Exercise 6, I will modify the `map` function of Exercise 1 slightly. For the `shuffle` and `reduce` operations, we can take advantage of functions written for Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ved9CtvMSju0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_full(line, column_indices):\n",
    "    \"\"\"\n",
    "    Create a tuple for flights depending on their occupancy rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Passengers, Seats, and\n",
    "        Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (int, int) or (None, None)\n",
    "        Each tuple is (dummy key, flight count). The dummy key\n",
    "        is 1 if the occupancy rate is 100% and 0 otherwise. The\n",
    "        return values is (None, None) if seats count is zero.\n",
    "\n",
    "    \"\"\"\n",
    "    passenger_idx, seats_idx, flights_idx = column_indices\n",
    "    passengers = int(line[passenger_idx])\n",
    "    seats = int(line[seats_idx])\n",
    "    try:\n",
    "        occupancy_rate = passengers / seats\n",
    "        flight_count = int(line[flights_idx])\n",
    "        if occupancy_rate == 1:\n",
    "            return 1, flight_count\n",
    "        else:\n",
    "            return 0, flight_count\n",
    "    except ZeroDivisionError:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "map_full_result = apply_map(FILENAME, map_full, columns1)\n",
    "map_full_result[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_full_result = shuffle_flights(map_full_result)\n",
    "shuffle_full_result[1.0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_full = apply_reduce(shuffle_full_result, reduce_flights)\n",
    "reduce_full.sort()\n",
    "reduce_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_full = reduce_full[1][1]\n",
    "print(f\"The number of full flights is {number_full}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_full = reduce_full[1][1] / (reduce_full[0][1]+reduce_full[1][1])\n",
    "print(f\"The share of full flights is {share_full*100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYM8qhAuSju5"
   },
   "source": [
    "\n",
    "### <strong> Exercise 6 -  Percentage of full flights </strong>\n",
    "#### <strong> 4 points </strong>\n",
    "\n",
    "<p align=\"justify\">\n",
    "Describe and implement a MapReduce procedure that gives, for each city, the percentage of full flights that have departed.\n",
    "\n",
    "Notice that this exercise shares some similarities with one of the previous exercises. Think how and if you can modify (generalize) one of the functions already implemented before. \n",
    "</font>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong> Answer </strong>\n",
    "Inside the `map` function of this exercise, I will delegate most of the computation to the `map` function of Exercise 5. Once again, the `shuffle` function of Exercise 1 will be re-used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPywU-Hu6UF7"
   },
   "outputs": [],
   "source": [
    "def map_proportion(line, column_indices):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list of str\n",
    "        Each line of a text file split into a list.\n",
    "    column_indices : list of int\n",
    "        List containing the indices of Origin_city, Passengers,\n",
    "        Seats, and Flights columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    city_idx = column_indices[0]\n",
    "    city = line[city_idx]\n",
    "    new_column_indices = column_indices[1:]\n",
    "    is_full_tuple = map_full(line, new_column_indices)\n",
    "    if is_full_tuple != (None, None):\n",
    "        return city, is_full_tuple\n",
    "    else:\n",
    "        return None, is_full_tuple\n",
    "\n",
    "\n",
    "columns6 = (\"Origin_city\", \"Passengers\", \"Seats\", \"Flights\")\n",
    "map_proportion_result = apply_map(FILENAME, map_proportion, columns6)\n",
    "map_proportion_result[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_proportion_result = shuffle_flights(map_proportion_result)\n",
    "shuffle_proportion_result[\"Los Angeles: CA\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_proportion(counts_dict, key):\n",
    "    \"\"\"\n",
    "    Compute the weighted average of all values for the given key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts_dict : dict of {hashable type : list of tuple}\n",
    "        Keys are the individual values of the grouping variable,\n",
    "        and values are the lists of tuples corresponding to same key.\n",
    "        The first element of each tuple is the value to be averaged,\n",
    "        and the second element is the corresponding weight.\n",
    "    key : hashable type\n",
    "        Individual value of the grouping variable for which we\n",
    "        need a weighted average.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (hashable type, float)\n",
    "        tuple of the form (key, weighted average of all values).\n",
    "\n",
    "    \"\"\"\n",
    "    value_weight_list = counts_dict[key]\n",
    "    sum_of_weights = 0\n",
    "    weighted_sum = 0\n",
    "    for value, weight in value_weight_list:\n",
    "        weighted_sum += value * weight\n",
    "        sum_of_weights += weight\n",
    "\n",
    "    weighted_mean = weighted_sum / sum_of_weights\n",
    "    return key, weighted_mean\n",
    "\n",
    "\n",
    "reduce_proportion_result = apply_reduce(shuffle_proportion_result, reduce_proportion)\n",
    "reduce_percent_result = [(key, share*100) for key, share in reduce_proportion_result]\n",
    "reduce_percent_result.sort(key=lambda x: x[1], reverse=True)\n",
    "reduce_percent_result[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o-3JT1L659s"
   },
   "source": [
    "#### <strong> Combine function </strong>\n",
    "Once again, it is not possible to use the `combine` operator. If processed parallelly by different machines, each input line produces only one key-value pair after the `map` function. That's why there are no other key-value pairs to combine."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "ass1_mapReduce_2021_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "name": "BE4-Spark.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
